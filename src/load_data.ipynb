{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will load our data\n",
    "# (DO NOT RUN THIS NOTEBOOK)\n",
    "# This is already done in advance, there is no need to use any of this notebook. Output is stored in data/loaded_data.json\n",
    "\n",
    "#### \n",
    "## Credits: Garvey Li, Kai Lee, Christian DerManuelian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cell below prepares our data (It should take several minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our data\n",
    "\n",
    "\"\"\" UNCOMMENT THESE LINES TO DOWNLOAD AND UNCOMPRESS DATA \"\"\"\n",
    "# from download_data import download_lmd_data, decompress_lmd_data\n",
    "# download_lmd_data()\n",
    "# decompress_lmd_data()\n",
    "\n",
    "\"\"\"\n",
    "# NOTE THE FUNCTION BELOW IS NOT NECESSARY AS IT'S OUTPUT IS ALREADY PROVIDED\n",
    "# See load_genre_data.py to see how we pulled genre data for the Lakh dataset\n",
    "\"\"\"\n",
    "# Get genre data\n",
    "# from load_genre_data import match_genres\n",
    "# match_genres('../data/lmd_matched_h5/', '../data/match_genre.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Packages from utils/ directory\n",
    "sys.path.insert(0, '../utils')\n",
    "import hdf5_getters as GETTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MetaData\n",
    "#### As of this stage, each song in our data folder has a .h5 file associated with it that contains that song's metadata.\n",
    "#### The data however has a weird nested structure\n",
    "#### The below cell creates a numpy array of each song's .h5 filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = \"../data/lmd_matched_h5/\"\n",
    "\n",
    "# Metadata filepath for each song\n",
    "metadata = np.array([])\n",
    "\n",
    "# Unnest the three alphabetic directories\n",
    "nest1 = os.listdir(fp)\n",
    "for l1 in nest1:\n",
    "    nest2 = os.listdir(fp + l1)\n",
    "    for l2 in nest2:\n",
    "        nest3 = os.listdir(fp + l1 +\"/\" + l2)\n",
    "        for l3 in nest3:\n",
    "            \n",
    "            # Get all the song's .h5 filepath for this level of nesting\n",
    "            curr_fp = fp + l1 + \"/\" + l2 + \"/\" + l3\n",
    "            files = os.listdir(curr_fp)\n",
    "\n",
    "            # Add them all to our 1d array\n",
    "            for md_f in files:\n",
    "                metadata = np.append(metadata, curr_fp + \"/\" + md_f)\n",
    "                \n",
    "metadata = np.unique(metadata)\n",
    "\n",
    "# Save these filepaths\n",
    "with open('../data/metadata.npy', 'wb') as f:\n",
    "    np.save(f, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorthand metadata read as we saved the output from the cell above\n",
    "with open('../data/metadata.npy', 'rb') as f:\n",
    "    metadata = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre\n",
    "#### Load genre data for each song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>genres</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAAAGR128F425B14B</th>\n",
       "      <td>Cyndi Lauper</td>\n",
       "      <td>Into The Nightlife</td>\n",
       "      <td>[rock, electronic, pop rock]</td>\n",
       "      <td>TRAAAGR128F425B14B.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAAAZF12903CCCF6B</th>\n",
       "      <td>Matthew Wilder</td>\n",
       "      <td>Break My Stride</td>\n",
       "      <td>[electronic, synth-pop, euro house]</td>\n",
       "      <td>TRAAAZF12903CCCF6B.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABVM128F92CA9DC</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>Caught In A Dream</td>\n",
       "      <td>[rock, electronic, pop]</td>\n",
       "      <td>TRAABVM128F92CA9DC.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAABXH128F42955D6</th>\n",
       "      <td>Brian Wilson</td>\n",
       "      <td>Keep An Eye On Summer (Album Version)</td>\n",
       "      <td>[rock, electronic, hip hop]</td>\n",
       "      <td>TRAABXH128F42955D6.h5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAACQE12903CC706C</th>\n",
       "      <td>Old Man River</td>\n",
       "      <td>Summer</td>\n",
       "      <td>[rock, electronic, synth-pop]</td>\n",
       "      <td>TRAACQE12903CC706C.h5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            artist                                   song  \\\n",
       "song_id                                                                     \n",
       "TRAAAGR128F425B14B    Cyndi Lauper                     Into The Nightlife   \n",
       "TRAAAZF12903CCCF6B  Matthew Wilder                        Break My Stride   \n",
       "TRAABVM128F92CA9DC           Tesla                      Caught In A Dream   \n",
       "TRAABXH128F42955D6    Brian Wilson  Keep An Eye On Summer (Album Version)   \n",
       "TRAACQE12903CC706C   Old Man River                                 Summer   \n",
       "\n",
       "                                                 genres               filename  \n",
       "song_id                                                                         \n",
       "TRAAAGR128F425B14B         [rock, electronic, pop rock]  TRAAAGR128F425B14B.h5  \n",
       "TRAAAZF12903CCCF6B  [electronic, synth-pop, euro house]  TRAAAZF12903CCCF6B.h5  \n",
       "TRAABVM128F92CA9DC              [rock, electronic, pop]  TRAABVM128F92CA9DC.h5  \n",
       "TRAABXH128F42955D6          [rock, electronic, hip hop]  TRAABXH128F42955D6.h5  \n",
       "TRAACQE12903CC706C        [rock, electronic, synth-pop]  TRAACQE12903CC706C.h5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load genre data as a pd dataframe\n",
    "json_match_fp = '../data/match_genre.json'\n",
    "genre_df = pd.read_json(json_match_fp) \n",
    "\n",
    "# Extract song id from metadata filename\n",
    "genre_df[\"song_id\"] = genre_df['filename'].str.replace(\".h5\", \"\")\n",
    "\n",
    "genre_df = genre_df.set_index(\"song_id\")\n",
    "genre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midi files\n",
    "#### Each song may have multiple midi files in our data\n",
    "#### We only need 1. Thankfully, match_scores.json from the Lakh dataset tells us which midi file is the best representation for that song. We will use this confidence dictionary in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/match_scores.json')\n",
    "confidence = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create our data\n",
    "#### The below cell defines a function to create our data in the format we want\n",
    "#### Our data is a list of dictionaries, where each dictionary an observation(song)\n",
    "#### Each dictionary contains these (features)keys (unique identifier, song title, filepath to the song's midi, list of genres, filepath to the song's metadata .h5 file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to have to break this into parts, because there is too much data for this loop to run on the current local machine that is running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create our dataset, we need to do it multiple times on subsets however\n",
    "# It takes in a list of metadata files\n",
    "# It reads each one, and creates a dictionary for that song (representing the feature vector)\n",
    "# It appends that dictionary to an output file as a json string\n",
    "def make_dataset(metadata_sub, out_fp, first_iteration=False):\n",
    "\n",
    "    # df filepath for our midi files\n",
    "    midi_df_fp = \"../data/lmd_aligned/\"\n",
    "\n",
    "    # For each song's metadata filepath\n",
    "    for md_fp in metadata_sub:\n",
    "        \n",
    "        # Read song's .h5 file\n",
    "        song_metadata = GETTERS.open_h5_file_read(md_fp)\n",
    "\n",
    "        # Extract the song's title as a string\n",
    "        song_name = song_metadata.root.metadata.songs.cols.title[:][0].decode('UTF-8')\n",
    "\n",
    "        # Extract the song's unique identifier in our dataset\n",
    "        song_id = md_fp.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        # Using our confidence data, get the id of midi file that is the best representation of this song \n",
    "        midi_id = max(confidence[song_id], key=confidence[song_id].get)\n",
    "\n",
    "        # Construct the filepath for the best choice midi file\n",
    "        midi_fp = (midi_df_fp + \"/\".join(md_fp.split(\"/\")[3:])).replace(\".h5\", \"\")  + \"/\" + midi_id + \".mid\"\n",
    "\n",
    "        # Get the list of this song's top 3 matching genres\n",
    "        try:\n",
    "            genres = genre_df.loc[song_id][\"genres\"]\n",
    "        # If we never got a genre for this song, don't include it\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Construct our feature vector for this observation\n",
    "        new_entry = {\"song_id\": song_id, \"title\": song_name, \"midi_fp\": midi_fp, \"genres\": genres, \"metadata\": md_fp}\n",
    "            \n",
    "        # Append it to our output file\n",
    "        with open(out_fp, 'a') as fout:\n",
    "            if (not first_iteration):\n",
    "                fout.write(\",\")\n",
    "            first_iteration=False\n",
    "            fout.write(json.dumps(new_entry, indent=4))\n",
    "        \n",
    "        # Clear up memory\n",
    "        del song_metadata\n",
    "        del song_name\n",
    "        del song_id\n",
    "        del midi_id\n",
    "        del midi_fp\n",
    "        del genres\n",
    "        del new_entry\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make metadata subset steps (as indices)\n",
    "#### Due to local machine memory issues, we did these splits manually for all 30k songs in steps, changing the metadata slice manually each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  500,  1000,  1500,  2000,  2500,  3000,  3500,  4000,  4500,\n",
       "        5000,  5500,  6000,  6500,  7000,  7500,  8000,  8500,  9000,\n",
       "        9500, 10000, 10500, 11000, 11500, 12000, 12500, 13000, 13500,\n",
       "       14000, 14500, 15000, 15500, 16000, 16500, 17000, 17500, 18000,\n",
       "       18500, 19000, 19500, 20000, 20500, 21000, 21500, 22000, 22500,\n",
       "       23000, 23500, 24000, 24500, 25000, 25500, 26000, 26500, 27000,\n",
       "       27500, 28000, 28500, 29000, 29500, 30000, 30500, 31034])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = 61\n",
    "n_k = 30500\n",
    "step_size = n_k // splits\n",
    "steps = []\n",
    "for i in range(splits):\n",
    "    steps.append(step_size*(i+1))\n",
    "steps += [len(metadata)]\n",
    "np.array(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = '../data/loaded_data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful this resets the .json file\n",
    "\n",
    "# # Create our empty output .json file\n",
    "# with open(out_fp, 'w') as fout:\n",
    "#     fout.write(\"[\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a subset (based on steps array)\n",
    "metadata_sub = metadata[30500:len(metadata)]\n",
    "\n",
    "make_dataset(metadata_sub, out_fp, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create our empty output .json file\n",
    "# with open(out_fp, 'a') as fout:\n",
    "#     fout.write(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore the cells below\n",
    "#### They were used to help the manual data loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/loaded_data.json', 'r') as fout:\n",
    "#     jstr = fout.read()\n",
    "#     jstr = '[' + jstr[1:] + ']'\n",
    "#     c = json.loads(jstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# x = np.array([d['song_id'] for d in c])\n",
    "# print(math.ceil(len(x) / 100) * 100)\n",
    "# len(x), len(np.unique(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
